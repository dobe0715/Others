{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNKAo855afPNQNdDUvryoSf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis"],"metadata":{"id":"V4Mb1uqH_3mW"}},{"cell_type":"markdown","source":["참고링크\n","+ blog\n","    + https://nuggy875.tistory.com/168\n","    + https://mvje.tistory.com/158\n","+ paper : https://arxiv.org/abs/2003.08934"],"metadata":{"id":"CwLqAXrk_3kD"}},{"cell_type":"markdown","source":["## Contribution\n","Neural Radiance Fields(NeRF)를 제안, 이를 효과적으로 최적화하여 복잡한 입체적인 물체의 novel view를 생성해낸다.  \n","(SOTA찍음)"],"metadata":{"id":"OpeDfKNG_5-t"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1nlyyJ90zOLeTmKhzJFcWP4WXR0K4HL-0\n","\" heigth=200>"],"metadata":{"id":"FBtsAwMNJSQ2"}},{"cell_type":"markdown","source":["## Method\n"],"metadata":{"id":"FiuFnNQk_58N"}},{"cell_type":"markdown","source":["논문은 3가지 흐름으로 이야기한다.\n","1. NeRF Scene Representation : 공간을 어떻게 표현했는가\n","2. Volume Rendering : 해당 공간 정보를 이용해 2D이미지 투시로 어떻게 재구성해낼 것인가\n","3. Optimizing NeRF : 성능을 위한 추가작업\n","    + Positional encoding\n","    + Hierarchical volume sampling"],"metadata":{"id":"6SGTOhN6_50R"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1BcKb48KWzJaOUJCSTaLojOPXk9VK4E1q\" height=250>"],"metadata":{"id":"mTTHiGcP_55n"}},{"cell_type":"markdown","source":["### NeRF Scene Representation"],"metadata":{"id":"zwfPXK-h_5xZ"}},{"cell_type":"markdown","source":["+ $\\mathbf{x} = (x, y, z)$ : 3D상의 절대적 위치좌표\n","+ $\\mathbf{d} = (\\theta, \\phi)$ : 2D viewing direction\n","+ $\\mathbf{c} = RGB$ : 해당 방향에서 바라봤을 때, 드러나는 색상\n","+ $\\sigma$ : volume density\n","+ $F_{\\Theta} : (\\mathbf{x}, \\mathbf{d}) \\rightarrow (\\mathbf{c}, \\sigma)$ : mapping network"],"metadata":{"id":"7U6vqk-E_521"}},{"cell_type":"markdown","source":["__Goal__   \n","특정한 좌표 $\\mathbf{x}$를 $\\mathbf{d}$라는 각도에서 바라보았을 때, 이에 해당하는 색상과 밀도를 반환해내는 모델(MLP)를 학습하는 것이다."],"metadata":{"id":"dauCwnhp_5u8"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=15mXmbvIyugWrWXJt9rrDYEzXxkAYk4Rm\" height=300>"],"metadata":{"id":"SEtKVlc9Ms_F"}},{"cell_type":"markdown","source":["+ 각 mlp마다 ReLU가 들어감.\n","+ 초록색은 input 값\n","+ \"+\" 표시는 concat\n","+ 붉은 색은 output 값"],"metadata":{"id":"TjoGP_FqM9GM"}},{"cell_type":"markdown","source":["### Volume Rendering with Radiance Fields"],"metadata":{"id":"OzJ-DqGm_5sd"}},{"cell_type":"markdown","source":["+ $\\mathbf{r}(t) = \\mathbf{o} + t\\mathbf{d}$ : $\\mathbf{d}$ 시점에서 바라본 camera ray의 직선의 방정식\n","+ $C(\\mathbf{r})$ : 해당 ray에서 보일 것으로 예상되는 color값"],"metadata":{"id":"16kxUcHW_5p0"}},{"cell_type":"markdown","source":["$C(\\mathbf{r}) = \\int^{t_f}_{t_n} T(t)\\sigma(\\mathbf{r}(t)\\mathbf{c}(\\mathbf{r}(t), \\mathbf{d}))dt$,  \n","where $T(t) = \\exp\\bigg(-\\int^t_{t_n}\\sigma(\\mathbf{r}(s))ds \\bigg)$"],"metadata":{"id":"J2Pqaj_x_5nN"}},{"cell_type":"markdown","source":["C(r)의 의미 : 해당 ray에서 바라본 color 값을 어떻게 예측하느냐??   \n","주어진 직선 r에 대해서, 물체의 near/far bound인 $t_n, t_f$까지의   \n","밀도 x color를 적분해준다.  \n","이 때, T라는 투과율(Transmittance) 값을 곱해주어 멀 수록 희미해지도록한다."],"metadata":{"id":"YUSXRkdW_5kr"}},{"cell_type":"markdown","source":["but, 컴퓨터가 계산하기 위해서는 discrete하게 바꿔줘야한다. => quadrature(구적법)"],"metadata":{"id":"SXaMnv6D_5iX"}},{"cell_type":"markdown","source":["간단하게, $[t_n, t_f]$의 구간을 $N$등분 한 점에 대해서 합해준다."],"metadata":{"id":"PEiVgplL_5gC"}},{"cell_type":"markdown","source":["$\\hat{C}(\\mathbf{r}) = \\sum^N_{i=1}T_i(1-\\exp(-\\sigma_i\\delta_i))\\mathbf{c}_i$,\n","where $T_i = \\exp\\bigg( -\\sum^{i-1}_{j=1}\\sigma_j\\delta_j \\bigg), \\delta_i = t_{i+1}-t_i$"],"metadata":{"id":"ExtzqkjI_5b2"}},{"cell_type":"markdown","source":["이 때, $\\sigma\\delta$가 아니라, $1-\\exp(-\\sigma\\delta)$를 곱해주는 건 수치적분적인 방법론이라고 한다.  \n","(좀더 smoothing하게 해준다??)"],"metadata":{"id":"rZNcdbbdQPDc"}},{"cell_type":"markdown","source":["### Optimizing a Neural Radiance Field"],"metadata":{"id":"ZUpqHfU4QPBv"}},{"cell_type":"markdown","source":["위의 방법은 분명 좋은 방법이지만... SOTA는 찍지 못했다고한다. 따라서, 두가지 추가적인 기법을 사용한다."],"metadata":{"id":"9og4REecQPAL"}},{"cell_type":"markdown","source":["#### Positional encoding"],"metadata":{"id":"fkarZecZQO-Z"}},{"cell_type":"markdown","source":["MLP의 입력값인 $\\mathbf{x}, \\mathbf{d}$를 higher dimensional space로 mapping해주면, model이 마찬가지로 high frequency한 variation에 대해 더 잘 data를 fitting해준다는 굉장히 reasonable한 생각으로 적용한 것이다."],"metadata":{"id":"DZrkJWwSQO7_"}},{"cell_type":"markdown","source":["$\\gamma : \\mathbb{R} \\rightarrow \\mathbb{R}^{2L}$  \n","$\\gamma(p) = (\\sin(2^0\\pi p), \\cos(2^0\\pi p), ..., \\sin(2^{L-1}\\pi p), \\cos(2^{L-1}\\pi p),)$"],"metadata":{"id":"Xj91-42jQO46"}},{"cell_type":"markdown","source":["$\\mathbf{x}$ : [-1,1]으로 normalize.L = 10   \n","$\\mathbf{d}$ : unit vector를 사용. L = 4"],"metadata":{"id":"Acq1I7PhQO2k"}},{"cell_type":"markdown","source":["다시 mlp를 보면...  \n","<img src=\"https://drive.google.com/uc?id=15mXmbvIyugWrWXJt9rrDYEzXxkAYk4Rm\" height=300>"],"metadata":{"id":"y438_zNoQO0T"}},{"cell_type":"markdown","source":["transformer에서도 마찬가지로 positional encoding을 통해   \n","이산적인 token들을 sequential하게 표현하기 위해서 적용한다."],"metadata":{"id":"qSTBoQKxQOyP"}},{"cell_type":"markdown","source":["하지만, 그와 다른 점은   \n","연속적인 input좌표를 high demensional space로 mapping해서 MLP가 더 high frequency function이 되도록 해주는 역할이다."],"metadata":{"id":"QmIn0HVHTwGK"}},{"cell_type":"markdown","source":["#### Hierarchical volume sampling"],"metadata":{"id":"VBQ7ZOONU_pz"}},{"cell_type":"markdown","source":["기존에 volume rendering하는 방법은 coarse한 color에 대해서 표현이 좋지만, fine한 부분에 대해서는 부족했다."],"metadata":{"id":"VlBOcJwPVAPO"}},{"cell_type":"markdown","source":["따라서 두가지 network를 최적화한다."],"metadata":{"id":"n-H3zHxlVoZv"}},{"cell_type":"markdown","source":["먼저, coarse는 앞에서 구한 것과 같다.  \n","$\\hat{C}_c(\\mathbf{r}) = \\sum^{N_c}_{i=1}w_i\\mathbf{c}_i$,\n","where $w_i = T_i(1-\\exp(-\\sigma_i\\delta_i))$"],"metadata":{"id":"Nzc1mnCNVoXO"}},{"cell_type":"markdown","source":["이제, 각 weight들을 $\\hat{w_i} = w_i / \\sum^{N_c}_{j=1}w_j$해주어 확률밀도함수형태로 normalizing해준다."],"metadata":{"id":"_NmZSkViVoUy"}},{"cell_type":"markdown","source":["그리고, 같은 ray에 대해서 위에서 구한 확률에 기반해서 $N_f$라는 fine locations set을 다시 셈플링해준다. 그리고 이를 통해 $\\hat{C}_f(\\mathbf{r})$을 계산해준다. 다만, 전체 color를 보존해주기 위해 $N_c+N_f$에 대해 계산해준다."],"metadata":{"id":"Xh6hvwsoVoSS"}},{"cell_type":"markdown","source":["$\\hat{C}_f(\\mathbf{r}) = \\sum^{N_c+N_f}_{i=1}w_i\\mathbf{c}_i$,\n","where $w_i = T_i(1-\\exp(-\\sigma_i\\delta_i))$"],"metadata":{"id":"23fsgFirVoOO"}},{"cell_type":"markdown","source":["최종적으로 optimiazation하기 위한 Loss term은 다음과 같다."],"metadata":{"id":"CLpQgTd5VoLN"}},{"cell_type":"markdown","source":["$\\mathcal{L} = \\sum_{r\\in\\mathcal{R}}\\bigg[||\\hat{C}_c(\\mathbf{r}) - C(\\mathbf{r})||^2_2 || + \\hat{C}_f(\\mathbf{r}) - C(\\mathbf{r})||^2_2 \\bigg]$"],"metadata":{"id":"LVmwu0fbTwDY"}},{"cell_type":"markdown","source":["$N_c=64, N_f=128$을 사용하였다."],"metadata":{"id":"v2rxTuXGTwAn"}},{"cell_type":"markdown","source":["## Experiment"],"metadata":{"id":"RcY7gIkFbc4s"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1wFYFJ2KCTo06qCGJBTzg7ZIZBgjNLM4s\" height=150>"],"metadata":{"id":"uWWWkO0Sbc1F"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=15RYd96-Oz6j27yuVtFGZAuB_8VnNdRkt\" height=200>"],"metadata":{"id":"2iC38AKKbcw8"}},{"cell_type":"markdown","source":[],"metadata":{"id":"Xi6Csi58bctw"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"oYFtPcv_bcMA"}}]}